{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deae77a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zavlyanova/Documents/00projects/Fil_rouge/fil-rouge\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1c9798-b3d7-4f81-bcc5-79549c8d66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des PDF\n",
    "import arxiv\n",
    "\n",
    "search = arxiv.Search(\n",
    "    # Seulement les sujets IA\n",
    "    query = \"cat:cs.AI\",\n",
    "    max_results = 30,\n",
    "    sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "paper = next(arxiv.Search(id_list=[\"1605.08386v1\"]).results())\n",
    "paper.download_pdf(dirpath=\"./papers\")\n",
    "\n",
    "for result in search.results():\n",
    "    result.download_pdf(dirpath=\"./papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2794859e-3245-4783-b7e5-a038ccb658c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "words = []\n",
    "labels = []\n",
    "\n",
    "for token in doc:\n",
    "\twords.append(token.text)\n",
    "\tlabels.append('O') # As most of token will be non-entity (OUT). Replace this later with actual entity a/c the scheme.\n",
    "\n",
    "df = pd.DataFrame({'word': words, 'label': labels})\n",
    "df.to_csv('ner-token-per-line.biluo', index=False) # biluo in extension to indicate the type of encoding, it is ok to keep csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d37f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages count: 25\n"
     ]
    }
   ],
   "source": [
    "dirpath=\"/home/zavlyanova/Documents/00projects/Fil_rouge/fil-rouge/papers/2201.11701v1.Model_Agnostic_Interpretability_for_Multiple_Instance_Learning.pdf\"\n",
    "\n",
    "# PDF TO TEXT\n",
    "\n",
    "from PyPDF2 import PdfFileReader\n",
    "import pdftotext\n",
    "\n",
    "# Extracting meta data\n",
    "with open(dirpath, \"rb\") as file:\n",
    "    data = pdftotext.PDF(file)\n",
    "    pdf = PdfFileReader(file)\n",
    "    info = pdf.getDocumentInfo()\n",
    "    number_of_pages = pdf.getNumPages()\n",
    "    author = info.author\n",
    "    creator = info.creator\n",
    "    producer = info.producer\n",
    "    subject = info.subject\n",
    "    title = info.title\n",
    "\n",
    "# print(\"Info:\", info)\n",
    "print(\"Pages count:\", number_of_pages)\n",
    "# print(\"Author:\", author)\n",
    "# print(\"Creator:\", creator)\n",
    "# print(\"Producer:\", producer)\n",
    "# print(\"Subject:\", subject)\n",
    "# print(\"Title:\", title)\n",
    "pdf_content = \"\\n\".join(data)\n",
    "# print(\"Content:\", pdf_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "093be14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Published as a preprint\n",
      "                                         M ODEL AGNOSTIC I NTERPRETABILITY FOR\n",
      "                                         M ULTIPLE I NSTANCE L EARNING\n",
      "                                          Joseph Early, Christine Evers & Sarvapali Ramchurn\n",
      "                                          Agents, Interaction and Complexity Group\n",
      "                                          Department of Electronics and Computer Science\n",
      "                                          University of Southampton\n",
      "                                          {J.A.Early, C.Evers, sdr1}@soton.ac.uk\n",
      "                                                                                       A BSTRACT\n",
      "arXiv:2201.11701v1 [cs.LG] 27 Jan 2022\n",
      "                                                     In Multiple Instance Learning (MIL), models are trained using bags of instances,\n",
      "                                                     where only a single label is provided for each bag. A bag label is often only\n",
      "                                                     determined by a handful of key instances within a bag, making it difficult to in-\n",
      "                                                     terpret what information a classifier is using to make decisions. In this work, we\n",
      "                                                     establish the key requirements for interpreting MIL models. We then go on to de-\n",
      "                                                     velop several model-agnostic approaches that meet these requirements. Our meth-\n",
      "                                                     ods are compared against existing inherently interpretable MIL models on several\n",
      "                                                     datasets, and achieve an increase in interpretability accuracy of up to 30%. We\n",
      "                                                     also examine the ability of the methods to identify interactions between instances\n",
      "                                                     and scale to larger datasets, improving their applicability to real-world problems.\n",
      "                                         1       I NTRODUCTION\n",
      "                                         In Multiple Instance Learning (MIL), data is organised into bags of instances, and each bag is given\n",
      "                                         a single label. This reduces the burden of labelling, as each instance does not have to be assigned a\n",
      "                                         label, making it useful in applications where labelling is expensive, such as healthcare (Carbonneau\n",
      "                                         et al., 2018). However, there are often only a few key instances within a bag that determine the bag\n",
      "                                         label, so it is necessary to identify these key instances in order to interpret a model’s decision-making\n",
      "                                         (Liu et al., 2012). Directly interpreting the decision-making process of machine learning methods is\n",
      "                                         difficult due to the complexity of the models and the scale of the data on which they trained, so there\n",
      "                                         is a need for methods that allow insights into the decision-making processes (Gilpin et al., 2018).\n",
      "                                         In MIL problems, only some of the instances in each bag will be discriminatory, i.e., a significant\n",
      "                                         number of the instances in a bag will be non-discriminatory or even related to other bag classes\n",
      "                                         (Amores, 2013). Identifying the important instances and presenting those as the interpretation of\n",
      "                                         model decision-making filters out the non-discriminatory information and provides the explainee\n",
      "                                         with a reduced and relevant interpretation, which will avoid overloading the user (Li et al., 2015).\n",
      "                                         Our work provides the following novel contributions:\n",
      "                                                  1. MIL interpretability definition We identify two questions that interpretability methods\n",
      "                                                     for MIL should be able to answer: 1) Which are the key instances for a bag? 2) What\n",
      "                                                     outcome (class/value) does each key instance support? In the rest of this work, we will refer\n",
      "                                                     to these two questions as the which and the what questions respectively. As we explore in\n",
      "                                                     Section 2, existing interpretability methods are able to answer which questions with varying\n",
      "                                                     degrees of accuracy, but can only answer what questions under certain assumptions.\n",
      "                                                  2. MIL model-agnostic interpretability methods Existing interpretability methods are of-\n",
      "                                                     ten model-specific, i.e., they can only be applied to certain types of MIL models. To this\n",
      "                                                     end, we build upon the state-of-the-art MIL inherent interpretability methods by develop-\n",
      "                                                     ing model-agnostic interpretability methods that are up to 30% more more accurate. The\n",
      "                                                     model-agnostic interpretability methods that we propose can be applied to any MIL model,\n",
      "                                                     and are able to answer both which and what questions.\n",
      "                                                  3. MIL interpretability method comparison We compare existing model-specific methods\n",
      "                                                     with our model-agnostic methods on several MIL datasets. Our experiments are also carried\n",
      "                                                     out on four types of MIL model, giving a comprehensive comparison of interpretability\n",
      "                                                     performance. To the best of the authors’ knowledge, this is one of the first studies to\n",
      "                                                     compare different interpretability methods for MIL.1\n",
      "                                             1\n",
      "                                                 Source code for this project is available at https://github.com/JAEarly/MILLI.\n",
      "                                                                                              1\n",
      "\n",
      "Published as a preprint\n",
      "The remainder of this work is laid out as follows. Section 2 provides relevant background knowledge\n",
      "and reviews existing MIL interpretability methods. Section 3 outlines the requirements for MIL\n",
      "interpretability and details our approaches that meet these requirements. Next, Section 4 provides\n",
      "our results and experiments. Section 5 discusses our findings, and Section 6 concludes.\n",
      "2     BACKGROUND AND RELATED WORK\n",
      "The standard MIL assumption (SMIL) is a binary problem with positive and negative bags (Di-\n",
      "etterich et al., 1997; Maron & Lozano-Pérez, 1998). A bag is positive if any of its instances are\n",
      "positive, otherwise it is negative. The assumptions of SMIL can be relaxed to allow more gener-\n",
      "alised versions of MIL, e.g., through extensions that include additional positive classes (Scott et al.,\n",
      "2005; Weidmann et al., 2003). SMIL also assumes there is no interaction between instances. How-\n",
      "ever, recent work has highlighted that modelling relationships between instances is beneficial for\n",
      "performance (Tu et al., 2019; Zhou et al., 2009). Existing methods for interpreting MIL models\n",
      "often rely on the SMIL assumption, so cannot generalise to other MIL problems. In addition, exist-\n",
      "ing methods are often model-specific, i.e., they only work for certain types of MIL models, which\n",
      "constrains the choice of model (Ribeiro et al., 2016a). Identifying the key instances in MIL bags is a\n",
      "form of local interpretability (Molnar, 2020), as the key instances are detected for a particular input\n",
      "to the model. Two of the key motivators for interpreting the decision-making process of a MIL sys-\n",
      "tem are reliability and trust — identifying the key instances allows an evaluation of the reliability of\n",
      "the system, which increases trust as the decision-making process becomes more transparent. In this\n",
      "work, we use the term interpretability rather than explainability to convey that the analysis remains\n",
      "tied to the models, i.e., these methods do not provide non-technical explanations in human terms.\n",
      "Under the SMIL assumption, which and what questions are equivalent — there are only two classes\n",
      "(positive and negative), and the only key instances are the instances that are positive, therefore once\n",
      "the key instances are identified, it is also known what outcome they support. However, when there\n",
      "are multiple positive classes, if instances from different classes co-occur in the same bags, answering\n",
      "which and what questions becomes two distinct problems. For example, some key instances will\n",
      "support one positive class, and some key instances will support another. Therefore, solely identifying\n",
      "which are the key instances does not answer the second question of what class they support. Existing\n",
      "methods, such as key instance detection (Liu et al., 2012), MIL attention (Ilse et al., 2018), and MIL\n",
      "graph neural networks (GNNs; Tu et al. (2019)) do not condition their output on a particular class,\n",
      "so it is not apparent what class each instance supports, i.e., they can only answer which questions.\n",
      "One existing method that can answer what questions is mi-Net (Wang et al., 2018), as it produces\n",
      "instance-level predictions as part of its processing. However, these instance-level predictions do\n",
      "not take account of interactions between the instances, so are often inaccurate. A related piece\n",
      "of work on MIL interpretability is Tibo et al. (2020), which considers interpretability within the\n",
      "scope of multi-multi-instance learning (MMIL; Tibo et al. (2017); Fuster et al. (2021)). In MMIL,\n",
      "the instances within a bag are arranged into into further bags, giving a hierarchical bags-of-bags\n",
      "structure. The interpretability techniques presented by Tibo et al. (2020) are model-specific as they\n",
      "are only designed for MMIL networks. In this work, we aim to overcome the limitations of existing\n",
      "methods by developing model-agnostic methods that can answer both which and what questions.\n",
      "In single instance supervised learning, model-agnostic techniques have been developed to interpret\n",
      "models. Post-hoc local interpretability methods, such as Local Interpretable Model-agnostic Ex-\n",
      "planations (LIME; Ribeiro et al. (2016b)) and SHapley Additive exPlanations (SHAP; Lundberg &\n",
      "Lee (2017)), work by approximating the original predictive model with a locally faithful surrogate\n",
      "model that is inherently interpretable. The surrogate model learns from simplified inputs that rep-\n",
      "resent perturbations of the original input that is being analysed. In this work, one of our proposed\n",
      "methods is a MIL-specific version of this approach.\n",
      "3     M ETHODOLOGY\n",
      "At the start of this section, we outline the requirements for MIL interpretability (Section 3.1). In\n",
      "Section 3.2, we propose three methods that meet these requirements under the assumption that there\n",
      "are no interactions between instances (independent-instance methods). In Section 3.3 we remove\n",
      "this assumption and propose our local surrogate model-agnostic interpretability method for MIL.\n",
      "                                                     2\n",
      "\n",
      "Published as a preprint\n",
      "3.1    MIL INTERPRETABILITY REQUIREMENTS\n",
      "A general MIL classification problem has C possible classes, with one class being negative and the\n",
      "rest being positive. This is a generalisation of the SMIL assumption, which is a special case when\n",
      "C = 2. An interpretability method that can only provide the general importance of an instance\n",
      "(without associating it with a particular class) can only answer which questions. In order to answer\n",
      "what questions, the method needs to state which classes each instance supports and refutes. For-\n",
      "mally, for a bag of instances X = {x1 , . . . , xk } and a bag classification function F , we want to\n",
      "assign a value to each instance that represents whether it supports or refutes a class c:\n",
      "                                         I(X, F, c) = {φ1 , . . . , φk }\n",
      "where I is the interpretability function and φi ∈ R is the interpretability value for instance i with\n",
      "respect to class c. Here, we assume that φi > 0 means instance i supports class c, φi < 0 implies\n",
      "instance i refutes class c, and the greater |φi |, the greater the importance of instance i. For some\n",
      "existing methods, such as attention, φi is the same for all classes, and φi ≥ 0 in all cases, so these\n",
      "requirements are not met. We later demonstrate these limitations in Section 5. In the next two\n",
      "sections we propose several model-agnostic methods that satisfy these requirements.\n",
      "3.2    D ETERMINING INSTANCE ATTRIBUTIONS\n",
      "In this section, we propose three model-agnostic methods for interpreting MIL models under the\n",
      "assumption that the instances are independent. This means we can observe the effects of each in-\n",
      "stance in isolation without worrying about interactions between the instances. We exploit a property\n",
      "of MIL models: the ability to deal with different sized bags. As MIL models are able to process\n",
      "bags of different sizes, it is possible to remove instances from the bags and observe any changes\n",
      "in prediction, allowing us to understand what instances are responsible for the model’s prediction.\n",
      "Below, we propose three methods that use this property to interpret a model’s decision making.\n",
      "Single Given a bag of instances X = {x1 , . . . , xk } and a bag classification function F , we can\n",
      "take each instance in turn and form a single instance bag: Xi = {xi } for i ∈ {1, . . . , k}. We then\n",
      "observe the model’s prediction on each single instance bag φi = Fc (Xi ), where Fc is the output of F\n",
      "for class c (i.e., the cth entry in the output vector of F (Xi )). A large value for φi suggests instance xi\n",
      "supports c, and a value close to zero suggest it has no effect with respect to class c. If we repeat this\n",
      "over all instances and all classes, we can build a picture of the classes that each instance supports,\n",
      "allowing us to answer what questions. However, this method cannot refute classes (i.e., φi ≥ 0 in\n",
      "all cases). It should be noted that this method gives the same outputs as the inherent interpretability\n",
      "of mi-Net (Wang et al., 2018), but here it is a model-agnostic rather than a model-specific method.\n",
      "One Removed A natural counterpart to the Single method is the One Removed method, where\n",
      "each instance is removed from the complete bag in turn, i.e., we form bags Xi = X \\ {xi }. For a\n",
      "particular class c, we can then observe the change in the model’s prediction caused by removing xi\n",
      "from the bag: φi = Fc (X)−Fc (Xi ). If the prediction decreases, xi supports c, and if it increases, xi\n",
      "refutes c, i.e., this method is able to both support and refute different classes. However, if there are\n",
      "other instances in the bag that support or refute class c, we may not observe a change in prediction\n",
      "when xi is removed, even if xi is a key instance.\n",
      "Combined In order to access the benefits of both the Single and One Removed methods, we can\n",
      "combine their outputs. A simple approach is to take the mean, i.e., φi = 21 [Fc ({xi }) + Fc (X) −\n",
      "Fc (X \\ {xi })]. This method can identify the important instances revealed by the Single method, and\n",
      "also refute outcomes as revealed by the One Removed method.\n",
      "With these three methods, it is assumed that there are no interactions between the instances. This\n",
      "is not true for all datasets, therefore, in the next section, we remove this assumption and propose a\n",
      "further method that is able to deal with the interactions between instances.\n",
      "3.3    D EALING WITH INSTANCE INTERACTIONS\n",
      "In order to calculate instance attributions whilst accounting for interactions between instances, we\n",
      "have to consider the effect of each instance within the context of the bag. With instance interactions,\n",
      "                                                       3\n",
      "\n",
      "Published as a preprint\n",
      "the co-occurrence of two (or more) instances changes the bag label from what it would be if the\n",
      "two instances were observed independently. The instances have different meanings depending on\n",
      "the context of the bag, i.e., on their own they mean something different to what they mean when\n",
      "observed together. One way to uncover these instance interactions is to perturb the original input\n",
      "to the model and observe the outcome. In the case of MIL, these perturbations can take the form\n",
      "of removing instances from the original bag. By sampling coalitions of instances, and fitting a\n",
      "weighted linear regression model against the coalitions and their respective model predictions, it is\n",
      "possible to construct a surrogate locally faithful interpretable model that accounts for the instance\n",
      "interactions in the original bag. A coalition is a binary vector z ∈ {0, 1}k that represents a subset\n",
      "S = {xi |zi = 1}, so the number of ones in the coalition |z| is equal to the length of the S. The\n",
      "surrogate model gc takes the form\n",
      "                                                           Xk\n",
      "                                           gc (z) = φ0 +       φi zi ,                                 (1)\n",
      "                                                           i=1\n",
      "where each coefficient φi ∈ {φ1 , . . . , φk } is the importance attribution for each instance xi ∈ X\n",
      "with respect to class c. Given a collection of n coalitions Z, minimising the loss function\n",
      "                                                  X\n",
      "                               L(Fc , gc , π) =       [Fc (S) − gc (z)]2 π(z),                         (2)\n",
      "                                                  z∈Z\n",
      "means gc is a locally faithful approximation of the original model F for class c. The loss function is\n",
      "weighted by a kernel π, which determines how important it is for gc to be faithful for each individual\n",
      "coalition. Here, gc only approximates F for class c, i.e., to produce interpretations for a bag with\n",
      "respect to all classes, a surrogate model needs to be fit for each class. Similar approaches have been\n",
      "applied in single instance supervised learning in methods such as LIME and KernelSHAP. Both use\n",
      "different choices for π: LIME employs l2 or cosine distance, and KernelSHAP uses a weighting\n",
      "scheme that approximates Shapley values (Shapley, 1953). For single instance supervised learning\n",
      "models, when perturbing the inputs, it is not possible to simply ‘remove’ a feature from an input as\n",
      "the models expect fixed-size inputs — either a new model has to be re-trained without that particular\n",
      "feature, or appropriate sampling from other data has to be undertaken, which can lead to unrealistic\n",
      "synthetic data. In MIL, as models are able to deal with different size bags, instances can be removed\n",
      "from the bags without the need for re-training or sampling from other data, meaning these issues do\n",
      "not occur in our setting.\n",
      "While it is possible utilise the weight kernels from LIME and KernelSHAP for MIL, we identify\n",
      "a significant drawback with both methods. Their choice for π weights all coalitions of the same\n",
      "size equally, i.e., they do not consider the content of the coalitions, only their size. Just because\n",
      "two coalitions are of the same size does not mean it is equally important that the surrogate model is\n",
      "faithful to both of them. Furthermore, the sampling strategies of both approaches lead to very large\n",
      "(|z| close to 1) or very small coalitions (|z| close to 0). Unless the number of samples n is very large,\n",
      "samples of average size (|z| close to 0.5) will not be chosen. As we see in Section 4.4, this approach\n",
      "to sampling is appropriate for some datasets, but not for others.\n",
      "We aim to overcome both of these drawbacks with our own MIL-specific choice of weight kernel and\n",
      "sampling approach. Below, we propose Multiple Instance Learning Local Interpretations (MILLI).\n",
      "At the core of our approach is a new method for weighting coalitions based on an initial ranking of\n",
      "instance importances ri ∈ {r1 , . . . , rk }. For a coalition z and ranking of instance importances r, we\n",
      "define our weight kernel πM as:\n",
      "                                          k\n",
      "                                     1 X\n",
      "                       πM (z, r) =            zi πR (ri ),                                             (3)\n",
      "                                    |z| i=0\n",
      "                                   (\n",
      "                                      (2α − 1)(1 − rki )e−β̂ri + 1 − α,        if β̂ ≥ 0,\n",
      "                  where πR (ri ) =                                                                     (4)\n",
      "                                      (1 − 2α)(1 + rik−k )e|β̂|(ri −k) + α, otherwise,\n",
      "                                   \u001a\n",
      "                                      β,       if α < 0.5,\n",
      "                          and β̂ =\n",
      "                                      −β, otherwise.\n",
      "πR is a function that weights instances based on their order in the ranking. Its two hyperparameters,\n",
      "α ∈ [0, 1] and β ∈ (−∞, ∞) define the shape of the function, and ultimately determine the kernel\n",
      "                                                        4\n",
      "\n",
      "Published as a preprint\n",
      "πM . The value of α dictates whether the sampling should be biased towards instances that are highly\n",
      "ranked or not: α > 0.5 means πR is biased towards instances higher in ordering, and α < 0.5 means\n",
      "πR is biased towards values lower in the ordering. The value of β is discussed below, as it becomes\n",
      "important when sampling coalitions. We provide an illustration of πR in Figure 1.\n",
      "                         Figure 1: The effect of α and β on πR (Equation 4).\n",
      "In πM , the coalition z is weighted on its content rather than its length, i.e., the distance between\n",
      "a subset and a bag is no longer determined simply by the number of instances removed. This is\n",
      "beneficial, as removing many non-discriminatory instances from the bag likely means the label of\n",
      "the bag remains the same, despite being different in size. Conversely, removing one discriminatory\n",
      "instance could change the bag label, even though the bag is only one instance smaller. As well as\n",
      "using πR in the weight kernel, we also utilise it to sample coalitions. We can consider the problem\n",
      "of sampling as a repeated coin toss, where P (zi = 1) = pi and P (zi = 0) = 1 − pi . In equal\n",
      "random sampling, every value pi ∈ {p1 , . . . , pk } is equal to 0.5, meaning E[|z|] = 0.5k. However,\n",
      "it is possible to improve upon equal random sampling by changing the value of p for each instance\n",
      "in bag, i.e., we can change the likelihood of each instance being involved in a coalition. To sample\n",
      "                                                                         Rk\n",
      "more informative coalitions, we set pi = πR (ri ), meaning E[|z|] = 0 πR dr:\n",
      "                              ( 2α−1 −β̂k\n",
      "                                  kβ̂ 2\n",
      "                                        (e     + β̂k − 1) + k(1 − α), if β̂ ≥ 0,\n",
      "                     E[|z|] = 1−2α                                                                          (5)\n",
      "                                  kβ̂ 2\n",
      "                                        (e−β̂k + β̂k − 1) + kα,            otherwise.\n",
      "If β < 0, the sampling is biased towards smaller coalitions, and if β > 0, the sampling is biased\n",
      "towards larger coalitions. The maximum and minimum E[|z|] is controlled by α. When α = 0.5 or\n",
      "β = 0, every value pi ∈ {p1 , . . . , pk } is equal to 0.5, meaning we have equal random sampling as\n",
      "described above. We provide an illustration of how E[|z|] changes in Figure 2.\n",
      "Figure 2: The effect of α and β on E[|z|] (Equation 4). We give the expected coalition size as a\n",
      "proportion of the bag size, i.e., E[|z|]/k.\n",
      "The final part of MILLI is how to determine the initial ranking of importances. For this, we can use\n",
      "the Single method from Section 3.2, which produces values {φ1 , . . . , φk }, and we convert this to an\n",
      "instance ranking: the new values {r1 , . . . , rk } represent the position for instance i in {φ1 , . . . , φk }\n",
      "(e.g., the instance with the greatest value for φ has r = 0). MILLI is more expensive to compute\n",
      "that the methods outlined in Section 3.2: O(Cnk 2 ) compared with O(Ck). However, when there\n",
      "are interactions between the instances, this extra complexity is required in order to build a better un-\n",
      "derstanding of the classes that each instance supports and refutes, allowing more accurate answering\n",
      "of what questions. It is important to note that MILLI is indeed model agnostic — it only requires\n",
      "access to the bag classification function F , and makes no assumptions about the underlying MIL\n",
      "model. As we demonstrate in the next section, this means we can apply it to any MIL model.\n",
      "                                                      5\n",
      "\n",
      "Published as a preprint\n",
      "4     E XPERIMENTS\n",
      "We apply our model-agnostic methods to seven MIL datasets. In this section, we detail the evaluation\n",
      "strategy (Section 4.1), the datasets (Section 4.2), models (Section 4.3), and results (Section 4.4). For\n",
      "implementation details, see Appendix A.1.\n",
      "4.1     E VALUATION STRATEGY\n",
      "For our evaluation, we do not assume that the interpretability methods have consistent output do-\n",
      "mains; we only assume a larger value implies larger support. Therefore, the best approach for\n",
      "evaluating the interpretability methods is to use ranking metrics — rather than looking at the ab-\n",
      "solute values produced by the methods, we compare the relative orderings they produce. As noted\n",
      "by Carbonneau et al. (2018), although a large number of benchmark MIL datasets exist, many do\n",
      "not have instance labels. Without instance labels, evaluating interpretability is challenging, as we\n",
      "do not have a ground truth instance ordering to compare to. We identify two appropriate evaluation\n",
      "metrics: for datasets with instance labels, we propose the use of normalised discounted cumulative\n",
      "gain at n (NDCG@n), and for datasets without instance labels, we propose the use of area under the\n",
      "perturbation curve compared with random orderings (AOPC-R; Samek et al. (2016)). While AOPC-\n",
      "R does not require instance labels, it is very expensive to compute. A significant difference between\n",
      "the two metrics is the way they weight the importance ordering: NDCG@n prioritises performance\n",
      "at the start of the ordering, whereas AOPC-R equally prioritises performance across the entire or-\n",
      "dering. We are the first to propose both of these metrics for use in evaluating MIL interpretability,\n",
      "and further discuss the advantages of both metrics in Appendix A.3.\n",
      "4.2     DATASETS\n",
      "Below we detail the three main datasets on which we can evaluate our interpretability methods.\n",
      "These datasets were selected as they have instance labels, so we can evaluate them using both\n",
      "NDCG@n and AOPC-R. However, we provide further results on the classical MIL datasets Musk,\n",
      "Tiger, Elephant and Fox in Appendix A.4 (Dietterich et al., 1997; Andrews et al., 2002).\n",
      "SIVAL The Spatially Independent, Variable Area, and Lighting (SIVAL; Rahmani et al. (2005))\n",
      "dataset consists of 25 classes of complex objects photographed in different environments, where\n",
      "each class contains 60 images. Each image has been segmented into approximately 30 segments,\n",
      "and each segment is represented by a 30-dimensional feature vector that encodes information such\n",
      "as the segment’s colour and texture. The segments are labelled as containing the object or containing\n",
      "background. We selected 12 of the 25 classes to be positive classes, and randomly sampled from the\n",
      "other 13 classes to form the negative class. For additional details see Appendix A.6.\n",
      "Four-class MNIST-Bags The SIVAL dataset has no co-occurrence of instances from different\n",
      "classes, i.e., each bag only contains one class of positive instances. Therefore, the which and what\n",
      "questions are the same. In order to explore what happens when there are different classes of positive\n",
      "instances in the same bag, we propose an extension of the MNIST-Bags dataset introduced by Ilse\n",
      "et al. (2018). Our extension, four-class MNIST-Bags (4-MNIST-Bags) is setup as follows: class 1 if\n",
      "8 in bag, class 2 if 9 in bag, class 3 in 8 and 9 in bag, and class 0 otherwise.2 In this dataset, answering\n",
      "what questions goes beyond answering which questions, e.g., the existence of an 8 supports classes\n",
      "one and three, but refutes classes zero and two. For further details see Appendix A.7.\n",
      "Colon Cancer To test the applicability of the interpretability methods on larger bag sizes, we apply\n",
      "it to colorectal cancer tissue classification. The ColoRectal Cancer (CRC) dataset (Sirinukunwattana\n",
      "et al., 2016) is a collection of microscopy images with annotated nuclei. We follow the same setup as\n",
      "Ilse et al. (2018), in which a bag is positive if it contains one or more nuclei from the epithelial class.\n",
      "This means the problem conforms to the SMIL assumption, and there are no interactions between\n",
      "instances. Each microscopy image is 500 x 500 pixels, and was split into 27 x 27 pixel patches to\n",
      "give a maximum of 324 patches per slide (patches were discarded if they contained mostly slide\n",
      "background). Not all of the instances are labelled, so we tailor our assessment using NDCG@n to\n",
      "only consider labelled instances. For additional details see Appendix A.8.\n",
      "    2\n",
      "      We use n to refer to an image from the MNIST dataset that represents the number n, even though that is\n",
      "not the assigned class label in the 4-MNIST-Bags dataset.\n",
      "                                                       6\n",
      "\n",
      "Published as a preprint\n",
      "4.3    M ODELS AND M ETHODS\n",
      "To highlight the model-agnostic abilities of the proposed methods, for each dataset, we trained four\n",
      "different types of multi-class MIL model: an embedding-based multiple instance neural network\n",
      "(MI-Net; Wang et al. (2018)), an instance-based multiple instance network (mi-Net; Wang et al.\n",
      "(2018)), an attention-based model (MI-Attn; Ilse et al. (2018)), and a graph neural network model\n",
      "(MI-GNN; Tu et al. (2019)). Aside from MI-Net, each of these models provide their own inherent\n",
      "interpretability method that we can compare our methods against. Additional details on the models\n",
      "are given in Appendix A.2. As well as evaluating our independent-instance methods and MILLI,\n",
      "we also compare against LIME and SHAP using both random and guided sampling (choosing coali-\n",
      "tions that maximise the weight kernel). This means that in total we are evaluating nine different\n",
      "interpretability methods: inherent interpretability, the three independent-instance methods (Section\n",
      "3.2), two LIME methods, two SHAP methods, and MILLI (Section 3.3). Note that, aside from the\n",
      "inherent interpretability methods, these methods are either novel (independent-instance methods and\n",
      "MILLI) or are applied to MIL for the time in this study (LIME and SHAP).\n",
      "4.4    R ESULTS\n",
      "For each dataset, we measured the performance of each interpretability method on each of the four\n",
      "MIL models. For the SIVAL dataset we measured the performance on only the negative class and\n",
      "the bag’s true class, but for all the other datasets we evaluated the interpretability over every class.\n",
      "This distinction was made as we know that each SIVAL bag can only contain instances from one\n",
      "positive class, therefore it is not necessary to evaluate over all possible classes. We present the\n",
      "interpretability results run against the test set for the SIVAL, 4-MNIST-Bags, and CRC datasets in\n",
      "Tables 1, 2 and 3 respectively. The results are averaged over ten repeat trainings of each model,\n",
      "and we also give the test accuracy of each of the underlying MIL models. We discuss our choice of\n",
      "hyperparameters in Appendix A.5.\n",
      "By analysing the NDCG@n interpretability results across these three datasets, we find that MILLI\n",
      "performs best with an average of 0.85, followed by the GuidedSHAP and Combined methods (both\n",
      "with an average of 0.81). For the average AOPC-R results (including the results on the classi-\n",
      "cal MIL datasets, see Appendix A.4), we find that Combined, GuidedSHAP, RandomLIME, and\n",
      "MILLI are the best performing methods, however the overall the difference in performance between\n",
      "the methods is much less than what we observe for the NDCG@n metric. For the 4-MNIST-Bags\n",
      "dataset, the difference in performance of MILLI on NDCG@n vs AOPC-R is due to the difference\n",
      "in weighting between the metrics: MILLI achieves a better ordering for the most important instances\n",
      "(outperforms other methods on NDCG@n), but gives the same ordering as other methods for less\n",
      "important instances (equal performance on AOPC-R). In the majority of cases, all of our proposed\n",
      "model-agnostic methods outperform the inherent interpretability methods, and are relatively consis-\n",
      "tent in performance across all models. For the SIVAL dataset, the independent-instance methods\n",
      "perform well, which is expected as the instances are independent. However, on the 4-MNIST-Bags\n",
      "Table 1: SIVAL interpretability NDCG@n / AOPC-R results. For all of the interpretability methods,\n",
      "the standard error of the mean was 0.01 or less.\n",
      "     Methods           MI-Net          mi-Net           MI-Attn       MI-GNN         Overall\n",
      "     Model Acc         0.819           0.808            0.813         0.781          0.805\n",
      "     Inherent          N/A             0.813 / 0.265 0.717 / 0.005 0.586 / 0.023 0.705 / 0.098\n",
      "     Single            0.825 / 0.280 0.813 / 0.266 0.801 / 0.302 0.734 / 0.194 0.793 / 0.261\n",
      "     One Removed 0.778 / 0.256 0.837 / 0.308 0.736 / 0.293 0.776 / 0.231 0.782 / 0.272\n",
      "     Combined          0.828 / 0.291 0.828 / 0.294 0.803 / 0.316 0.762 / 0.227 0.805 / 0.282\n",
      "     RandomSHAP        0.801 / 0.284   0.807 / 0.300    0.766 / 0.322 0.784 / 0.250  0.789 / 0.289\n",
      "     GuidedSHAP        0.826 / 0.291   0.819 / 0.290    0.790 / 0.313 0.765 / 0.235  0.800 / 0.282\n",
      "     RandomLIME        0.809 / 0.295   0.815 / 0.310    0.776 / 0.335 0.793 / 0.258  0.798 / 0.299\n",
      "     GuidedLIME        0.780 / 0.259   0.830 / 0.310    0.742 / 0.296 0.776 / 0.233  0.782 / 0.274\n",
      "     MILLI             0.823 / 0.283 0.827 / 0.307 0.794 / 0.307 0.790 / 0.239 0.808 / 0.284\n",
      "                                                     7\n",
      "\n",
      "Published as a preprint\n",
      "Table 2: 4-MNIST-Bags interpretability NDCG@n / AOPC-R results. The MI-GNN model takes\n",
      "four times as long for a single model pass than the other models, so calculating its AOPC-R results on\n",
      "this dataset was infeasible (see Appendix A.3). For all of the interpretability methods, the standard\n",
      "error of the mean was 0.01 or less.\n",
      "       Methods          MI-Net          mi-Net           MI-Attn        MI-GNN       Overall\n",
      "       Model Acc        0.971           0.974            0.967          0.966        0.970\n",
      "       Inherent         N/A / N/A       0.723 / 0.136 0.750 / 0.002 0.419 / N/A 0.630 / 0.069\n",
      "       Single           0.722 / 0.138 0.723 / 0.137 0.778 / 0.164 0.761 / N/A 0.746 / 0.146\n",
      "       One Removed 0.811 / 0.187 0.810 / 0.186 0.809 / 0.143 0.786 / N/A 0.804 / 0.172\n",
      "       Combined         0.775 / 0.184 0.775 / 0.185 0.816 / 0.183 0.804 / N/A 0.792 / 0.184\n",
      "       RandomSHAP       0.813 / 0.186   0.809 / 0.185    0.825 / 0.178  0.828 / N/A  0.819 / 0.183\n",
      "       GuidedSHAP       0.773 / 0.187   0.773 / 0.188    0.816 / 0.183  0.805 / N/A  0.792 / 0.186\n",
      "       RandomLIME       0.828 / 0.189   0.825 / 0.189    0.841 / 0.179  0.838 / N/A  0.833 / 0.186\n",
      "       GuidedLIME       0.760 / 0.189   0.756 / 0.187    0.785 / 0.145  0.776 / N/A  0.769 / 0.174\n",
      "       MILLI            0.947 / 0.190 0.943 / 0.189 0.917 / 0.181 0.959 / N/A 0.942 / 0.186\n",
      "Table 3: CRC interpretability NDCG@n results. As this dataset has much larger bag sizes (264\n",
      "instances per bag on average), it is infeasible to compute its AOPC-R results (see Appendix A.3).\n",
      "For all of the interpretability methods, the standard error of the mean was 0.02 or less.\n",
      "                    Methods          MI-Net mi-Net MI-Attn MI-GNN Overall\n",
      "                    Model Acc        0.795       0.795    0.830     0.770      0.797\n",
      "                    Inherent         N/A         0.845    0.692     0.684      0.740\n",
      "                    Single           0.815       0.845    0.847     0.786      0.823\n",
      "                    One Removed 0.698            0.682    0.701     0.815      0.724\n",
      "                    Combined         0.815       0.845    0.846     0.803      0.827\n",
      "                    RandomSHAP       0.695       0.690    0.717     0.703      0.701\n",
      "                    GuidedSHAP       0.815       0.845    0.846     0.804      0.827\n",
      "                    RandomLIME       0.695       0.702    0.716     0.813      0.731\n",
      "                    GuidedLIME       0.687       0.699    0.701     0.818      0.726\n",
      "                    MILLI            0.753       0.800    0.810     0.780      0.786\n",
      "dataset, MILLI excels as it samples informative coalitions that capture the instance interactions. On\n",
      "the CRC dataset, methods that are able to isolate individual instances, (i.e., the Single, Combined,\n",
      "and GuidedSHAP methods) perform well due to instance independence in this dataset. Further-\n",
      "more, if we consider the witness rate (WR; the proportion of key instances in each bag; Carbonneau\n",
      "et al. (2018)) of the datasets, we find that the CRC dataset has a higher WR (27.47%) than SIVAL\n",
      "(15.28%) and 4-MNIST-Bags (8.04%). This means, with larger coalitions, it becomes more difficult\n",
      "to isolate the contributions of individual instances, which is why the One Removed and Random\n",
      "sampling methods struggle.\n",
      "5     D ISCUSSION\n",
      "To demonstrate how MILLI captures instance interactions, and to show the limitations of existing\n",
      "methods that cannot condition their output for a particular class, we compare the MILLI interpre-\n",
      "tations with the attention interpretations on the 4-MNIST-Bags dataset (Figure 3). As this bag con-\n",
      "tains an 8 and a 9, the correct label for it is class three. Both the MILLI and attention methods have\n",
      "identified the 8 and 9 instances as key instances, i.e., they have both answered the which question.\n",
      "However, only MILLI correctly identifies that the 8 refutes class two and that the 9 refutes class\n",
      "one, answering the what question, something that the attention values do not do. We provide further\n",
      "examples, including interpretability outputs for the SIVAL and CRC datasets, in Appendix A.10.\n",
      "                                                      8\n",
      "\n",
      "Published as a preprint\n",
      "Figure 3: An example of the identification of key instances for the 4-MNIST-Bags experiment. The\n",
      "top row shows the attention value for each instance, and bottom three rows show the output of MILLI\n",
      "for classes three, two, and one respectively (green = support, red = refute).\n",
      "LIME, SHAP, and MILLI all require the number of sampled coalitions to be selected. A greater\n",
      "number of coalitions means there is more data to fit the surrogate model on, therefore it is more likely\n",
      "to faithful to the underlying model. However, the more samples that are taken, the more expensive\n",
      "the computation. As shown in Figure 4, MILLI is the most consistent in terms of performance and\n",
      "efficiency. For all methods, it is a case of diminishing returns, where additional samples only lead\n",
      "to a small increase in performance.\n",
      "Figure 4: The effect of sample size on interpretability performance for the MI-Attn model. We\n",
      "provide the results of the same study but for the other MIL models in Appendix A.9.\n",
      "The different sampling approaches used in this work have distinct advantages. When there are in-\n",
      "teractions between instances, RandomSHAP and RandomLIME are better than GuidedSHAP and\n",
      "GuidedLIME as they form larger coalitions that are more likely to capture the instance interac-\n",
      "tions. However, for the CRC dataset, where there are a large number of independent instances and\n",
      "a high WR, RandomSHAP, RandomLIME and GuidedLIME struggle as they cannot form small\n",
      "coalitions. MILLI performs relatively well across all datasets as the size of its sampled coalitions\n",
      "can be adapted depending on the dataset, demonstrating its generalisability. However, it is still out-\n",
      "performed by GuidedSHAP on the CRC dataset. One possible explanation for this is that MILLI\n",
      "is limited to sampling only smaller or larger coalitions, whereas GuidedSHAP samples both large\n",
      "and small coalitions. One approach for improving MILLLI would be to incorporate paired sampling\n",
      "(Covert & Lee, 2020), where for every sampled coalition zi , we also sample its complement coali-\n",
      "tion 1 − zi . Following the advice of Carbonneau et al. (2018), further MIL studies on more complex\n",
      "datasets, such as Pascal VOC (Everingham et al., 2010), could also be insightful for evaluating MIL\n",
      "interpretability methods. It would also be beneficial to examine if these techniques are applicable to\n",
      "MIL domains beyond classification, e.g. MIL regression as in Wang et al. (2020).\n",
      "6    C ONCLUSION\n",
      "In this work, we have discussed the process of model-agnostic interpretability for MIL. Along with\n",
      "defining the requirements for MIL interpretability, we have presented our own approaches and com-\n",
      "pared them to existing inherently interpretable MIL models. By analysing the methods across sev-\n",
      "eral datasets, we have shown that independent-instance methods can be effective, but local surrogate\n",
      "methods are required when there are interactions between the instances. All of our proposed meth-\n",
      "ods are more effective than existing inherently interpretable models, and are able to not only identify\n",
      "which are the key instances, but also say what classes they support and refute.\n",
      "                                                   9\n",
      "\n",
      "Published as a preprint\n",
      "R EPRODUCIBILITY S TATEMENT\n",
      "For our work, the main details for the methodology are detailed in Section 3. In addition, we provide\n",
      "details that will aid reproducibility in the Appendix. The dataset sources and a general overview of\n",
      "our implementation is given in Appendix A.1. Further information on the MIL models used in\n",
      "this work can be found in Appendix A.2, and specific details on their architectures and training\n",
      "can be found in Appendices A.6, A.7, and A.8 for the SIVAL, 4-MNIST-Bags, and CRC datasets\n",
      "respectively. The codebase for this work can be found on GitHub: https://github.com/\n",
      "JAEarly/MILLI.\n",
      "ACKNOWLEDGEMENTS\n",
      "The authors acknowledge the use of the IRIDIS High Performance Computing Facility and associ-\n",
      "ated support services at the University of Southampton in the completion of this work. IRIDIS-5\n",
      "GPU-enabled compute nodes were used for the long running experiments in this work.\n",
      "We also acknowledge the use of SciencePlots (Garrett, 2021) for formatting our Matplotlib figures.\n",
      "This work was funded by AXA Research Fund and the UKRI Trustworthy Autonomous Systems\n",
      "Hub (EP/V00784X/1).\n",
      "R EFERENCES\n",
      "Jaume Amores. Multiple instance classification: Review, taxonomy and comparative study. Artificial\n",
      "   intelligence, 201:81–105, 2013.\n",
      "Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann.             Support vector machines for\n",
      "   multiple-instance learning. In NIPS, volume 2, pp. 7, 2002.\n",
      "Marc-André Carbonneau, Veronika Cheplygina, Eric Granger, and Ghyslain Gagnon. Multiple in-\n",
      "   stance learning: A survey of problem characteristics and applications. Pattern Recognition, 77:\n",
      "   329–353, 2018.\n",
      "Ian Covert and Su-In Lee. Improving kernelshap: Practical shapley value estimation via linear\n",
      "   regression. arXiv preprint arXiv:2012.01536, 2020.\n",
      "Thomas G Dietterich, Richard H Lathrop, and Tomás Lozano-Pérez. Solving the multiple instance\n",
      "   problem with axis-parallel rectangles. Artificial intelligence, 89(1-2):31–71, 1997.\n",
      "Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman.\n",
      "   The pascal visual object classes (voc) challenge. International journal of computer vision, 88(2):\n",
      "   303–338, 2010.\n",
      "Saul Fuster, Trygve Eftestøl, and Kjersti Engan. Nested multiple instance learning with attention\n",
      "   mechanisms. arXiv preprint arXiv:2111.00947, 2021.\n",
      "John D. Garrett. garrettj403/SciencePlots. September 2021. doi: 10.5281/zenodo.4106649. URL\n",
      "   http://doi.org/10.5281/zenodo.4106649.\n",
      "Leilani H Gilpin, David Bau, Ben Z Yuan, Ayesha Bajwa, Michael Specter, and Lalana Kagal.\n",
      "   Explaining explanations: An overview of interpretability of machine learning. In 2018 IEEE\n",
      "   5th International Conference on data science and advanced analytics (DSAA), pp. 80–89. IEEE,\n",
      "   2018.\n",
      "Maximilian Ilse, Jakub Tomczak, and Max Welling. Attention-based deep multiple instance learn-\n",
      "   ing. In International conference on machine learning, pp. 2127–2136. PMLR, 2018.\n",
      "Sirui Li, Weixing Sun, and Tim Miller. Communication in human-agent teams for tasks with joint\n",
      "   action. In International Workshop on Coordination, Organizations, Institutions, and Norms in\n",
      "   Agent Systems, pp. 224–241. Springer, 2015.\n",
      "Guoqing Liu, Jianxin Wu, and Zhi-Hua Zhou. Key instance detection in multi-instance learning. In\n",
      "   Asian Conference on Machine Learning, pp. 253–268. PMLR, 2012.\n",
      "                                                  10\n",
      "\n",
      "Published as a preprint\n",
      "Scott Lundberg and Su-In Lee. A unified approach to interpreting model predictions. arXiv preprint\n",
      "  arXiv:1705.07874, 2017.\n",
      "Oded Maron and Tomás Lozano-Pérez. A framework for multiple-instance learning. Advances in\n",
      "  neural information processing systems, pp. 570–576, 1998.\n",
      "Christoph Molnar. Interpretable machine learning. Lulu. com, 2020.\n",
      "Rouhollah Rahmani, Sally A Goldman, Hui Zhang, John Krettek, and Jason E Fritts. Localized\n",
      "  content based image retrieval. In Proceedings of the 7th ACM SIGMM international workshop on\n",
      "  Multimedia information retrieval, pp. 227–236, 2005.\n",
      "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Model-agnostic interpretability of ma-\n",
      "  chine learning. arXiv preprint arXiv:1606.05386, 2016a.\n",
      "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. ”Why should I trust you?” Explaining the\n",
      "  predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference\n",
      "  on knowledge discovery and data mining, pp. 1135–1144, 2016b.\n",
      "Wojciech Samek, Alexander Binder, Grégoire Montavon, Sebastian Lapuschkin, and Klaus-Robert\n",
      "  Müller. Evaluating the visualization of what a deep neural network has learned. IEEE transactions\n",
      "  on neural networks and learning systems, 28(11):2660–2673, 2016.\n",
      "Stephen Scott, Jun Zhang, and Joshua Brown. On generalized multiple-instance learning. Interna-\n",
      "  tional Journal of Computational Intelligence and Applications, 5(01):21–35, 2005.\n",
      "Lloyd S Shapley. A value for n-person games. Princeton University Press, 1953.\n",
      "Korsuk Sirinukunwattana, Shan E Ahmed Raza, Yee-Wah Tsang, David RJ Snead, Ian A Cree, and\n",
      "  Nasir M Rajpoot. Locality sensitive deep learning for detection and classification of nuclei in\n",
      "  routine colon cancer histology images. IEEE transactions on medical imaging, 35(5):1196–1206,\n",
      "  2016.\n",
      "Alessandro Tibo, Paolo Frasconi, and Manfred Jaeger. A network architecture for multi-multi-\n",
      "  instance learning. In Joint European Conference on Machine Learning and Knowledge Discovery\n",
      "  in Databases, pp. 737–752. Springer, 2017.\n",
      "Alessandro Tibo, Manfred Jaeger, and Paolo Frasconi. Learning and interpreting multi-multi-\n",
      "  instance learning networks. J. Mach. Learn. Res., 21:193–1, 2020.\n",
      "Ming Tu, Jing Huang, Xiaodong He, and Bowen Zhou. Multiple instance learning with graph neural\n",
      "  networks. arXiv preprint arXiv:1906.04881, 2019.\n",
      "Kaili Wang, Jose Oramas, and Tinne Tuytelaars. In defense of lstms for addressing multiple instance\n",
      "  learning problems. In Proceedings of the Asian Conference on Computer Vision, 2020.\n",
      "Xinggang Wang, Yongluan Yan, Peng Tang, Xiang Bai, and Wenyu Liu. Revisiting multiple instance\n",
      "  neural networks. Pattern Recognition, 74:15–24, 2018.\n",
      "Nils Weidmann, Eibe Frank, and Bernhard Pfahringer. A two-level learning method for generalized\n",
      "  multi-instance problems. In European Conference on Machine Learning, pp. 468–479. Springer,\n",
      "  2003.\n",
      "Zhi-Hua Zhou, Yu-Yin Sun, and Yu-Feng Li. Multi-instance learning by treating instances as non-\n",
      "  iid samples. In Proceedings of the 26th annual international conference on machine learning, pp.\n",
      "  1249–1256, 2009.\n",
      "                                                  11\n",
      "\n",
      "Published as a preprint\n",
      "A     A PPENDIX\n",
      "A.1    I MPLEMENTATION DETAILS\n",
      "All code for this work was implemented in Python 3.8, using the PyTorch library for the machine\n",
      "learning functionality. Hyperparameter tuning was carried out using the Optuna libary. Some lo-\n",
      "cal experiments were carried out on a Dell XPS Windows laptop, utilising a GeForce GTX 1650\n",
      "graphics card with 4GB of VRAM. GPU support for machine learning was enabled through CUDA\n",
      "v11.0. Other longer running experiments, such as hyperparameter tuning, were carried out on a re-\n",
      "mote GPU node utilising a Volta V100 Enterprise Compute GPU with 16GB of VRAM. The longest\n",
      "model to train was the GNN for the CRC dataset, which took just under half an hour. The longest\n",
      "running experiment was the hyperparameter analysis for the CRC dataset at just under 40 hours.\n",
      "This was due to high number of samples for the local surrogate methods and the fact that the results\n",
      "were average over 10 different models. The randomisation of data splits was fixed using seeding;\n",
      "the seed values are provided in the code for each experiment. We use the following sources for our\n",
      "data:\n",
      "        • The annotated SIVAL dataset was downloaded from the publicly accessible page:\n",
      "          http://pages.cs.wisc.edu/˜bsettles/data/.\n",
      "        • The MNIST dataset was access directly from the PyTorch Python library:\n",
      "          https://pytorch.org/vision/stable/datasets.html#mnist.\n",
      "        • The CRC dataset was downloaded from the publicly accessible page:\n",
      "          https://warwick.ac.uk/fac/cross_fac/tia/data/crchistolabelednucleihe/.\n",
      "        • The Musk dataset was downloaded from the publicly accessible page:\n",
      "          https://archive.ics.uci.edu/ml/datasets/Musk+%28Version+2%29\n",
      "        • The Tiger, Elephant and Fox datasets were downloaded from the publicly accessible page:\n",
      "          http://www.cs.columbia.edu/˜andrews/mil/datasets.html\n",
      "A.2    M ODELS\n",
      "In this work, we trained four different models for each dataset. In this section, we provide further\n",
      "details on each of the models. Each model was tuned independently for each dataset, so in the later\n",
      "sections we provide details of the specific architectures for each dataset. We also tuned the learning\n",
      "rate, weight decay, and dropout for each of the models independently for every dataset. Again, these\n",
      "are given in the later sections for each specific dataset.\n",
      "MI-Net Each instance is embedded to a fixed size, and then these embeddings are aggregated to\n",
      "give a single bag embedding. This aggregation can either take the mean (mil-mean) or max (mil-\n",
      "max) of the instance embeddings. The bag embedding is then classified to give an overall bag\n",
      "prediction. For this model, we tuned the number and size of fully connected (FC) layers, as well as\n",
      "the choice of aggregation function.\n",
      "mi-Net A prediction is made for each individual instance, and then these are aggregated to a\n",
      "single outcome for the bag as a whole. Similar to the MI-Net model, we tuned the FC layers and the\n",
      "aggregation function.\n",
      "MI-Attn Each instance is embedded to a fixed size, and then the mil-attn block produces an atten-\n",
      "tion value for each instance embedding. The instance embeddings are then aggregated to a single\n",
      "bag embedding by performing a weighted sum based on the attention values. The bag embedding\n",
      "is then classified to give an overall bag prediction. The mil-attn block is the same as per the MIL\n",
      "attention mechanism proposed by Ilse et al. (2018), i.e., using a single hidden layer. We tuned the\n",
      "the number and size of the FC layers, as well as the size of the hidden attention layer.\n",
      "MI-GNN The GNN model treats the bag as a fully connected graph and uses graph convolutions\n",
      "to propagate information between instances. Initially, the original instances are embedded to a\n",
      "fixed size. These instance embeddings are then passed onto a GNNembed block and a GNNcluster\n",
      "block, the output of which is used to reduce the graph representation down into a single embedding\n",
      "using differentiable pooling (gnn-pool). The final bag representation is then classified to give an\n",
      "overall bag prediction. For more details see Tu et al. (2019). We tuned the number and size of the\n",
      "embedding, GNN, and classifier layers.\n",
      "                                                   12\n",
      "\n",
      "Published as a preprint\n",
      "A.3      E VALUATION METRICS\n",
      "In this section, we provide further details on how we use normalised discounted cumulative gain at\n",
      "n (NDCG@n) to evaluate the interpretability methods for datasets with instance labels, and how we\n",
      "use area under the perturbation curve with random orderings (AOPC-R) to evaluate the interpretabil-\n",
      "ity methods for datasets without instance labels.\n",
      "NDCG@n To use NDCG@n, we first need a ground truth ordering to compare to. For a particular\n",
      "class, we can place each instance into one of three groups based on their ground truth instance labels:\n",
      "supporting instances, neutral instances, and refuting instances. The ideal instance ordering for that\n",
      "class would then have all of the supporting instances at the beginning, followed by all the neutral\n",
      "instances, and then all of the refuting instances at the end. Then, given interpretability outputs\n",
      "{φ1 , . . . , φk } for a particular class, we rank the outputs from highest to lowest, i.e., in order of\n",
      "how much they support that class. This importance ordering is then compared to the ground truth\n",
      "ordering using the follow metric:\n",
      "                                                              n\n",
      "                                                         1 X rel(i)\n",
      "                                     NDCG@n =                                 ,\n",
      "                                                      IDCG i=1 log2 (i + 1)\n",
      "                                                       n\n",
      "                                                      X         1\n",
      "                                   where IDCG =                        .\n",
      "                                                      i=1\n",
      "                                                          log2 (i + 1)\n",
      "IDCG is the ideal discounted cumulative gain that normalises the scores across different values of\n",
      "n. The relevance function rel(i) is as follows:\n",
      "                                      if the ith instance in the ranking supports the class,\n",
      "                              \n",
      "                              1\n",
      "                     rel(i) = −1      if the ith instance in the ranking refutes the class,\n",
      "                              \n",
      "                                0     otherwise.\n",
      "AOPC-R Although originally designed for single instance supervised learning, here we adapt\n",
      "AOPC-R for MIL. Given an importance ordering, AOPC successively removes the most relevant\n",
      "instances (i.e., those at the start of the given importance ordering), and measures the change in\n",
      "prediction. A better ordering will show a more rapid decrease in prediction, as instances that are\n",
      "more supportive will be removed first. This rate of decrease in prediction with respect to class\n",
      "c for a classifier F and bag X = {x1 , . . . , xk } is measured as follows: given the ordered bag\n",
      "OX = {o1 , . . . , ok } (which is just X ordered by instance importance, with the most important\n",
      "instances at the start),\n",
      "                                                         k−1\n",
      "                                                    1 X                      (i)\n",
      "                                     AOPC =                  Fc (X) − Fc (XM oRF ),                  (6)\n",
      "                                                  k − 1 i=1\n",
      "                                      (0)\n",
      "                             where XM oRF = X,                                                       (7)\n",
      "                                      (i)           (i−1)\n",
      "                               and XM oRF     =  XM oRF    \\ {oi }.                                  (8)\n",
      "To normalise the results, one approach is to measure the average difference in AOPC for the given\n",
      "ordering to the AOPC of several random orderings:\n",
      "                                                  r\n",
      "                                             1X\n",
      "                               AOPC-R =              AOPC(OX ) − AOPC(ORi ),                         (9)\n",
      "                                             r i=1\n",
      "where r is the number of random orderings, and ORi is the ith random ordering of X. The repeated\n",
      "calls to Fc make AOPC-R very expensive to compute. This can be reduced by examining the p first\n",
      "perturbations rather than all k − 1 possible perturbations, but that was not something we investigated\n",
      "in this work (we kept p = k and r = 10). Furthermore, due to the use of random orderings, this\n",
      "evaluation metric is inherently stochastic, meaning not only do we have variance in the orderings\n",
      "produced in the methods (e.g., from random sampling), we also have variance due to measurement.\n",
      "NDCG@n does not have either of the issues (i.e., its cheap to compute and deterministic), however\n",
      "it requires (at least some) instance labels.\n",
      "                                                         13\n",
      "\n",
      "Published as a preprint\n",
      "A.4    A DDITIONAL RESULTS\n",
      "In this section, we detail our additional results on the Musk and Tiger, Elephant & Fox (TEF) clas-\n",
      "sical MIL datasets. Although these datasets do not have instance labels, since they are widely used\n",
      "MIL datasets, it is useful to see how our interpretability methods perform on them. Each of these\n",
      "datasets are instance independent, and as they have a low number of instances per bag, we adapted\n",
      "our local surrogate methods to allow sampling with repeats (otherwise we cannot sample enough\n",
      "coalitions). In our previous experiments, we restricted the local surrogate methods to sampling\n",
      "without repeats, which was not an issue with the larger bag sizes in the SIVAL, 4-MNIST-Bags, and\n",
      "CRC datasets. For each of these classic datasets, we used the same model hyperparameters that we\n",
      "used for SIVAL (see Appendix A.6), i.e., we didn’t retune the training parameters or model archi-\n",
      "tectures. However, we did tune the parameters for the interpretability methods, which we discuss\n",
      "in Appendix A.5. We give the interpretability results as well as the model performance for Musk\n",
      "(Table A1), Tiger (Table A2), Elephant (Table A3), and Fox (Table A4) below.\n",
      "Table A1: Musk interpretability AOPC-R results. Note that we are using the Musk1 dataset, rather\n",
      "than Musk2, as the latter has much larger bag sizes, making the use of AOPC-R infeasible.\n",
      "  Methods           MI-Net            mi-Net           MI-Attn         MI-GNN         Overall\n",
      "  Model Acc         0.871 ± 0.024 0.836 ± 0.027 0.793 ± 0.029 0.793 ± 0.028 0.823 ± 0.016\n",
      "  Inherent          N/A               0.108 ± 0.010 0.002 ± 0.015 0.003 ± 0.006 0.036 ± 0.011\n",
      "  Single            0.123 ± 0.010 0.108 ± 0.010 0.113 ± 0.010 0.090 ± 0.010 0.108 ± 0.010\n",
      "  One Removed 0.108 ± 0.009 0.107 ± 0.010 0.088 ± 0.008 0.076 ± 0.009 0.095 ± 0.009\n",
      "  Combined          0.124 ± 0.010 0.107 ± 0.010 0.116 ± 0.010 0.088 ± 0.010 0.109 ± 0.010\n",
      "  RandomSHAP        0.115 ± 0.009     0.104 ± 0.010    0.110 ± 0.009   0.077 ± 0.009  0.102 ± 0.009\n",
      "  GuidedSHAP        0.122 ± 0.009     0.106 ± 0.010    0.116 ± 0.010   0.084 ± 0.009  0.107 ± 0.009\n",
      "  RandomLIME        0.113 ± 0.009     0.107 ± 0.010    0.110 ± 0.009   0.080 ± 0.009  0.102 ± 0.009\n",
      "  GuidedLIME        0.117 ± 0.009     0.106 ± 0.010    0.102 ± 0.008   0.077 ± 0.009  0.101 ± 0.009\n",
      "  MILLI             0.117 ± 0.009 0.105 ± 0.010 0.109 ± 0.009 0.084 ± 0.010 0.104 ± 0.009\n",
      "                           Table A2: Tiger interpretability AOPC-R results.\n",
      "  Methods           MI-Net            mi-Net           MI-Attn         MI-GNN         Overall\n",
      "  Model Acc         0.827 ± 0.024 0.807 ± 0.029 0.807 ± 0.019 0.800 ± 0.028 0.810 ± 0.005\n",
      "  Inherent          N/A               0.124 ± 0.005 0.001 ± 0.007 0.000 ± 0.003 0.042 ± 0.005\n",
      "  Single            0.132 ± 0.005 0.125 ± 0.005 0.120 ± 0.005 0.082 ± 0.003 0.115 ± 0.004\n",
      "  One Removed 0.123 ± 0.005 0.127 ± 0.005 0.114 ± 0.004 0.081 ± 0.003 0.111 ± 0.004\n",
      "  Combined          0.130 ± 0.005 0.127 ± 0.005 0.124 ± 0.005 0.082 ± 0.003 0.116 ± 0.004\n",
      "  RandomSHAP        0.124 ± 0.004     0.122 ± 0.005    0.121 ± 0.005   0.080 ± 0.003  0.112 ± 0.004\n",
      "  GuidedSHAP        0.130 ± 0.005     0.125 ± 0.005    0.121 ± 0.005   0.082 ± 0.003  0.115 ± 0.004\n",
      "  RandomLIME        0.128 ± 0.005     0.125 ± 0.005    0.119 ± 0.005   0.081 ± 0.003  0.113 ± 0.004\n",
      "  GuidedLIME        0.129 ± 0.005     0.125 ± 0.005    0.122 ± 0.005   0.082 ± 0.003  0.115 ± 0.004\n",
      "  MILLI             0.128 ± 0.005 0.125 ± 0.005 0.120 ± 0.004 0.081 ± 0.003 0.114 ± 0.004\n",
      "We find that there is very little difference in interpretability performance for each of our proposed\n",
      "methods across these four datasets. This is to be expected, as the instances are independent, there-\n",
      "fore the independent-instance methods as well as the local surrogate methods are able to identify the\n",
      "important instances, i.e., there is little to be gained by sampling coalitions when each instance can\n",
      "be understood in isolation. However, this reinforces the applicability of all of our proposed meth-\n",
      "ods. We note that the attention and GNN inherent interpretability methods perform poorly in these\n",
      "experiments — this is because they are unable to condition their outputs on a specific class (i.e., they\n",
      "can only answer which questions, not what questions). We also note that the performance is much\n",
      "worse on the Fox dataset. Here, the underlying MIL models perform poorly, so it is unsurprising\n",
      "that the interpretability methods also perform poorly.\n",
      "                                                     14\n",
      "\n",
      "Published as a preprint\n",
      "                           Table A3: Elephant interpretability AOPC-R results.\n",
      "  Methods           MI-Net            mi-Net          MI-Attn        MI-GNN          Overall\n",
      "  Model Acc         0.857 ± 0.017 0.863 ± 0.017 0.867 ± 0.016 0.853 ± 0.020 0.860 ± 0.003\n",
      "  Inherent          N/A               0.130 ± 0.006 0.000 ± 0.006 0.000 ± 0.003 0.043 ± 0.005\n",
      "  Single            0.127 ± 0.004 0.131 ± 0.006 0.127 ± 0.005 0.105 ± 0.004 0.122 ± 0.005\n",
      "  One Removed 0.117 ± 0.004 0.129 ± 0.006 0.105 ± 0.005 0.103 ± 0.004 0.114 ± 0.005\n",
      "  Combined          0.126 ± 0.004 0.130 ± 0.006 0.127 ± 0.005 0.106 ± 0.004 0.122 ± 0.005\n",
      "  RandomSHAP        0.124 ± 0.004     0.126 ± 0.006   0.119 ± 0.005  0.102 ± 0.004   0.118 ± 0.005\n",
      "  GuidedSHAP        0.127 ± 0.004     0.130 ± 0.006   0.124 ± 0.005  0.105 ± 0.004   0.122 ± 0.005\n",
      "  RandomLIME        0.124 ± 0.004     0.128 ± 0.006   0.121 ± 0.005  0.104 ± 0.004   0.119 ± 0.005\n",
      "  GuidedLIME        0.123 ± 0.004     0.130 ± 0.006   0.118 ± 0.005  0.104 ± 0.004   0.119 ± 0.005\n",
      "  MILLI             0.124 ± 0.005 0.128 ± 0.006 0.121 ± 0.005 0.103 ± 0.005 0.119 ± 0.005\n",
      "                              Table A4: Fox interpretability AOPC-R results.\n",
      "  Methods           MI-Net            mi-Net          MI-Attn        MI-GNN          Overall\n",
      "  Model Acc         0.600 ± 0.011 0.610 ± 0.017 0.620 ± 0.023 0.580 ± 0.013 0.603 ± 0.007\n",
      "  Inherent          N/A               0.050 ± 0.002 0.001 ± 0.002 0.000 ± 0.001 0.017 ± 0.002\n",
      "  Single            0.044 ± 0.002 0.049 ± 0.002 0.041 ± 0.002 0.021 ± 0.001 0.039 ± 0.002\n",
      "  One Removed 0.043 ± 0.002 0.049 ± 0.002 0.040 ± 0.002 0.021 ± 0.001 0.038 ± 0.002\n",
      "  Combined          0.044 ± 0.002 0.050 ± 0.002 0.041 ± 0.002 0.021 ± 0.001 0.039 ± 0.002\n",
      "  RandomSHAP        0.044 ± 0.002     0.049 ± 0.002   0.041 ± 0.002  0.021 ± 0.001   0.039 ± 0.002\n",
      "  GuidedSHAP        0.045 ± 0.002     0.050 ± 0.002   0.042 ± 0.002  0.021 ± 0.001   0.040 ± 0.002\n",
      "  RandomLIME        0.044 ± 0.002     0.050 ± 0.002   0.041 ± 0.002  0.021 ± 0.001   0.039 ± 0.002\n",
      "  GuidedLIME        0.044 ± 0.002     0.050 ± 0.002   0.041 ± 0.002  0.021 ± 0.001   0.039 ± 0.002\n",
      "  MILLI             0.043 ± 0.002 0.049 ± 0.002 0.041 ± 0.002 0.022 ± 0.001 0.039 ± 0.002\n",
      "A.5    I NTERPRETABILITY METHOD HYPERPARAMETER SELECTION\n",
      "In this section we discuss our method for hyperparameter selection in the interpretability methods,\n",
      "and detail the hyperparameters that we found to be most effective. An advantage of the inherent\n",
      "interpretability and independent-instance methods is that they do not have hyperparameters, i.e., we\n",
      "only had to select hyperparameters for the local surrogate interpretability methods. First, we discuss\n",
      "our choice of hyperparameters for LIME, and then our choice of hyperparameters for MILLI.\n",
      "LIME hyperparameters When using the LIME weight kernel, there are two hyperparameters to\n",
      "tune. Firstly, the distance measures that are commonly used are L2 and cosine distance. In our\n",
      "experiments, we found very little difference between each of these distance measures, therefore\n",
      "we arbitrarily chose to use L2 distance in all of our experiments. The second hyperparameter is\n",
      "the kernel width, which determines the weighting of coalitions, i.e., a large kernel width means all\n",
      "coalitions are weighted more evenly, and a small kernel width prioritises larger coalitions. We chose\n",
      "to use a kernel width for all of our experiments that is determined by the average bag size, such that\n",
      "the half coalition (i.e., |z| = 0.5k) is weighted at 0.5.\n",
      "MILLI hyperparameters For MILLI, there were three hyperparameters to tune: the number of\n",
      "samples, α, and β. For the number of samples, we generated sample size plots such as Figure 4\n",
      "(also see Appendix A.9), and chose the number of samples to be at the point where all the methods\n",
      "had reasonably converged. For α and β we ran a grid search over the possible values, and chose the\n",
      "best performing pair of parameters. The hyperparameters were tuned for each dataset, except for\n",
      "the TEF datasets, in which we only tuned on Tiger and then used the same hyperparameters across\n",
      "                                                    15\n",
      "\n",
      "Published as a preprint\n",
      "all three datasets. In Table A5, we provide the chosen hyperparameters for each dataset, as well as\n",
      "the expected coalition size E[|z|] determined by α and β. For the CRC, Musk and TEF datasets,\n",
      "the chosen parameters produce small values for E[|z|], i.e., the sampling is heavily biased towards\n",
      "smaller coalitions, which is expected as these are instance independent datasets. Conversely, the\n",
      "parameters for the 4-MNIST-Bags focus on sampling larger coalitions that are able to capture the\n",
      "instance interactions in the dataset. Although the SIVAL dataset is instance independent, the pa-\n",
      "rameters also focus on sampling larger coalitions. This could be because, although the instances are\n",
      "independent, it may be difficult to classify an object from just one instance, i.e., several instances\n",
      "are needed to make the correct decision. We also note that, in all cases, α < 0.5, i.e., the sampling\n",
      "is biased towards instances ranked lower in the initial importance ordering used by MILLI. Our ex-\n",
      "planation for this is that it is easy to understand the contribution of discriminatory instances, as they\n",
      "have a large effect on the model prediction, but it is more difficult to understand the contribution of\n",
      "non-discriminatory instances, as they have much less of an effect. Therefore, more samples contain-\n",
      "ing non-discriminatory instances are required to properly understand their effect, hence biasing the\n",
      "sampling towards them.\n",
      "                                    Table A5: MILLI hyperparameters.\n",
      "                          Dataset            Sample Size α         β       E[|z|]\n",
      "                          SIVAL              200            0.05   -0.01   13\n",
      "                          4-MNIST-Bags       150            0.05   0.01    16\n",
      "                          CRC                1000           0.008  -5.0    2\n",
      "                          MUSK               150            0.3    -1.0    2\n",
      "                          TEF                150            0.3    0.01    3\n",
      "A.6     SIVAL EXPERIMENT DETAILS\n",
      "Dataset For the SIVAL dataset, each instance is represented by a 30-dimensional feature vector,\n",
      "and there are around 30 instances per bag. We chose 12 of the 25 original classes to be the positive\n",
      "classes, and randomly selected 30 images from each of the other 13 classes to form the negative\n",
      "class, meaning overall we had 13 classes (12 positive and one negative). In total, we had 60 bags\n",
      "for each of the 12 positive classes, and 390 bags for the single negative class, meaning the class\n",
      "distribution was ≈ 5.4% for each positive class and ≈ 35.1% for the negative class. The arbitrarily\n",
      "chosen positive classes were: apple, banana, checkeredscarf, cokecan, dataminingbook, goldmedal,\n",
      "largespoon, rapbook, smileyfacedoll, spritecan, translucentbowl, and wd40can. We normalised each\n",
      "instance according to the dataset mean and standard deviation. No other data augmentation was used.\n",
      "The dataset was separated into train, validation, and test data using an 80/10/10 split. This was done\n",
      "with stratified sampling in order to maintain the same data distribution across all splits.\n",
      "Training When training models against the SIVAL dataset, we used a batch size of one, i.e., a\n",
      "single bag of, on average, 30 instances. We trained the models to minimise cross entropy loss\n",
      "using the Adam optimiser; the hyperparamater details for learning rate (LR), weight decay (WD)\n",
      "and dropout (DO) are given in Table A6. We utilised early stopping based on validation loss — if\n",
      "the validation loss had not decreased for 10 epochs then we terminated the training procedure and\n",
      "reset the model to the point at which it caused the last decrease in validation loss. Otherwise, the\n",
      "maximum number of epochs was 100. The tuned architectures for each model are given in Tables\n",
      "A7 to A10, and the results for each model are comapred in Table A11.\n",
      "        Table A6: SIVAL hyperparameters.                   Table A7: SIVAL MI-Net architecture.\n",
      "       Model       LR            WD        DO             Layer Type                  Input Output\n",
      "       Mi-Net      5 × 10−3      1 × 10−3  0.45           1       FC + ReLU + DO      30     128\n",
      "       mi-Net      5 × 10−4      1 × 10−5  0.25           2       FC + ReLU + DO      128    256\n",
      "       MI-Attn     1 × 10−3      1 × 10−5  0.15           3       mil-max             256    256\n",
      "       MI-GNN      5 × 10−4      1 × 10−5  0.2            4       FC                  256    13\n",
      "                                                     16\n",
      "\n",
      "Published as a preprint\n",
      "       Table A8: SIVAL mi-Net architecture.             Table A9: SIVAL MI-Attn architecture.\n",
      "      Layer Type                  Input Output         Layer Type                   Input Output\n",
      "      1       FC + ReLU + DO      30     512           1      FC + ReLU + DO        30    128\n",
      "      2       FC + ReLU + DO      512    256           2      FC + ReLU + DO        128   256\n",
      "      3       FC + ReLU + DO      256    64            3      FC + ReLU + DO        256   128\n",
      "      4       FC                  64     13            4      mil-attn(256) + DO    128   128\n",
      "      5       mil-mean            13     13            5      FC                    128   13\n",
      "                               Table A10: SIVAL MI-GNN architecture.\n",
      "                        Layer          Type                       Input Output\n",
      "                        1              FC + ReLU + DO             30    128\n",
      "                        2a GNNembed SAGEConv + ReLU + DO 128            128\n",
      "                                       SAGEConv + ReLU + DO 128         256\n",
      "                                       SAGEConv + ReLU + DO 256         64\n",
      "                        2b GNNcluster SAGEConv + Softmax          128   1\n",
      "                        3              gnn-pool                   64    64\n",
      "                        4              FC + ReLU + DO             64    128\n",
      "                        5              FC                         128   13\n",
      "Table A11: SIVAL model results. The mean performance was calculated over ten repeat trainings\n",
      "of each model, and the standard error of the mean is given.\n",
      "                        Model     Train Accuracy Val Accuracy Test Accuracy\n",
      "                        MI-Net    0.984 ± 0.004   0.850 ± 0.009   0.819 ± 0.012\n",
      "                        mi-Net    0.967 ± 0.005   0.835 ± 0.010   0.808 ± 0.011\n",
      "                        MI-Attn   0.972 ± 0.007   0.830 ± 0.011   0.813 ± 0.012\n",
      "                        MI-GNN    0.932 ± 0.014   0.803 ± 0.014   0.781 ± 0.019\n",
      "A.7     4-MNIST-BAGS EXPERIMENT DETAILS\n",
      "Dataset In the 4-MNIST-Bags experiments, the bag sizes were draw from a normal distribution,\n",
      "with a mean of 30 and a variance of 2. We used 2500 training bags, 1000 validation bags, and 1000\n",
      "test bags. The instances in the training bags were only drawn from the original MNIST training\n",
      "split, and the instances in the validation and test bags were only drawn from the original MNIST\n",
      "test split, i.e., there was no overlap between training, validation, and test instances. The classes\n",
      "were balanced, so, on average, there were 625 bags per class in the training data, and 250 bags per\n",
      "class in the validation and test data. We normalised the MNIST images using the PyTorch normalise\n",
      "transformation, with a mean of 0.1307 and a stand deviation of 0.3081. No other data augmentation\n",
      "was carried out.\n",
      "Training The training procedure was the same as for the SIVAL experiments: a batch size of one,\n",
      "early stopping with a patience of ten, and a maximum of 100 epochs. The training hyperparamater\n",
      "details are given in Table A12. For each model, we first passed the MNIST instances through a\n",
      "convolutional architecture to produce initial instance embeddings. This encoder was not tuned for\n",
      "each model (i.e., the architecture was fixed, but the weights were learnt). The architecture for this\n",
      "encoder is given in Table A13, and then the model architectures are given in Tables A14 to A17. The\n",
      "encoder produces features vectors with 800 features, therefore the input size to each of the models\n",
      "is 800. The model results are given in Table A18.\n",
      "                                                  17\n",
      "\n",
      "Published as a preprint\n",
      "                                                   Table A13: 4-MNIST-Bags convolutional encod-\n",
      "                                                   ing architecture. For the convolutional (Conv2d)\n",
      "   Table A12: 4-MNIST-Bags hyperparameters. and pooling (MaxPool2d) layers, the numbers\n",
      "       Model      LR        WD          DO         in the brackets are the kernel size, stride, and\n",
      "                                                   padding.\n",
      "       MI-Net 1 × 10−4 1 × 10−3 0.3\n",
      "                                                     Layer Type                         Input Out\n",
      "       mi-Net 1 × 10−4 1 × 10−4 0.3\n",
      "                        −4          −4\n",
      "       MI-Attn 1 × 10       1 × 10      0.15         1      Conv2d(5, 1, 0) + ReLU 1          20\n",
      "       MI-GNN 5 × 10−5 1 × 10−5 0.3                  2      MaxPool2d(2, 2, 0) + DO 20        20\n",
      "                                                     3      Conv2d(5, 1, 0) + ReLU 20         50\n",
      "                                                     4      MaxPool2d(2, 2, 0) + DO 50        50\n",
      "                                                   Table A15: 4-MNIST-Bags mi-Net architecture.\n",
      " Table A14: 4-MNIST-Bags MI-Net architecture.\n",
      "                                                       Layer Type                 Input Output\n",
      "     Layer Type                 Input Output\n",
      "                                                       1       FC + ReLU + DO     800    512\n",
      "     1       FC + ReLU + DO     800    128\n",
      "                                                       2       FC + ReLU + DO     512    128\n",
      "     2       FC + ReLU + DO     128    512\n",
      "                                                       3       FC + ReLU + DO     128    64\n",
      "     3       mil-mean           512    512\n",
      "                                                       4       FC                 128    4\n",
      "     4       FC                 512    4\n",
      "                                                       5       mil-mean           4      4\n",
      "                         Table A16: 4-MNIST-Bags MI-Attn architecture.\n",
      "                      Layer Type                       Input size Output size\n",
      "                      1       FC + ReLU + Dropout      800         64\n",
      "                      2       FC + ReLU + Dropout      64          256\n",
      "                      3       mil-attn(64) + Dropout   256         256\n",
      "                      4       FC + ReLU + Dropout      256         64\n",
      "                      5       FC                       64          4\n",
      "                         Table A17: 4-MNIST-Bags MI-GNN architecture.\n",
      "               Layer         Type                               Input size Output size\n",
      "               1             FC + ReLU + Dropout                800        64\n",
      "               2             FC + ReLU + Dropout                64         64\n",
      "               3a GNNembed SAGEConv + ReLU + Dropout 64                    128\n",
      "                             SAGEConv + ReLU + Dropout 128                 128\n",
      "                             SAGEConv + ReLU + Dropout 128                 128\n",
      "               3b GNNcluster SAGEConv + Softmax                 64         1\n",
      "               4             gnn-pool                           128        128\n",
      "               5             FC + ReLU + Dropout                128        64\n",
      "               6             FC                                 64         4\n",
      "Table A18: 4-MNIST-Bags model results. The mean performance was calculated over ten repeat\n",
      "trainings of each model, and the standard error of the mean is given.\n",
      "                     Model     Train Accuracy Val Accuracy Test Accuracy\n",
      "                     MI-Net    0.995 ± 0.001     0.972 ± 0.002    0.971 ± 0.002\n",
      "                     mi-Net    0.993 ± 0.001     0.973 ± 0.002    0.974 ± 0.002\n",
      "                     MI-Attn   0.991 ± 0.002     0.967 ± 0.003    0.967 ± 0.003\n",
      "                     MI-GNN    0.984 ± 0.002     0.968 ± 0.002    0.966 ± 0.002\n",
      "                                                 18\n",
      "\n",
      "Published as a preprint\n",
      "A.8     CRC EXPERIMENT DETAILS\n",
      "Dataset In the CRC dataset, there are 100 microscopy images, and each image is annotated with\n",
      "four classes of nuclei: epithelial, inflammatory, fibroblast, and miscellaneous. Of these 100 images,\n",
      "50 are in the negative class (no epithelial nuclei), and 50 are in the positive class (at least one\n",
      "epithelial nuclei). Each image is 500 x 500 pixels, and was split into 27 x 27 pixel patches to give\n",
      "324 patches per slide. The patches were created by applying a non-overlapping grid over the image,\n",
      "where each cell of the grid was a 27 x 27 pixel region. The alternative would be to extract patches\n",
      "centred on each marked nuclei (as done by Ilse et al. (2018)), however this method then requires\n",
      "the nuclei to be marked for unseen data. This accounts for the difference between our results and\n",
      "the results of Ilse et al. (2018) — extracting the patches using a fixed grid will include patches that\n",
      "do not contain any marked nuclei, increasing the amount of non-discriminatory data in each bag\n",
      "and thus making the problem harder to learn. We removed slide background patches by using a\n",
      "brightness threshold — any patch with an average pixel value above 230 (using pixel values 0 to\n",
      "255) was discarded. This left an average of 264 patches per image, and one image was discarded\n",
      "as it had zero foreground patches (this was also manually verified). The images were normalised\n",
      "using the dataset mean (0.8035, 0.6499, 0.8348) and standard deviation (0.0858, 0.1079, 0.0731).\n",
      "During training, we also applied three transformations to patches at random: horizontal flips, vertical\n",
      "flips, and 90 degree rotations. The dataset was separated into train, validation, and test data using a\n",
      "60/20/20 split. This was done with stratified sampling in order to maintain the same data distribution\n",
      "across all splits.\n",
      "Training The training procedure was the same as for the SIVAL and 4-MNIST-Bags experiments:\n",
      "a batch size of one, early stopping with a patience of ten, and a maximum of 100 epochs. The training\n",
      "hyperparamater details are given in Table A19. Following the same procedure as the 4-MNIST-Bags\n",
      "experiments, for each model, we first passed the patches through a convolutional architecture to\n",
      "produce initial instance embeddings. The architecture for this encoder is given in Table A20, and\n",
      "then the model architectures are given in Tables A21 to A24. The encoder produces features vectors\n",
      "with 1200 features, therefore the input size to each of the models is 1200. The model results are\n",
      "given in Table A25.\n",
      "                                                     Table A20: CRC convolutional encoding archi-\n",
      "    Table A19: CRC training hyperparameters.         tecture. For the convolutional (Conv2d) and\n",
      "                                                     pooling (MaxPool2d) layers, the numbers in the\n",
      "        Model      LR          WD         DO         brackets are the kernel size, stride, and padding.\n",
      "        MI-Net     5 × 10−4    1 × 10−3   0.3          Layer Type                           Input Out\n",
      "        mi-Net     5 × 10−4    1 × 10−2   0.25\n",
      "                                                       1       Conv2d(4, 1, 0) + ReLU       3     36\n",
      "        MI-Attn    1 × 10−3    1 × 10−6   0.2\n",
      "                                                       2       MaxPool2d(2, 2, 0) + DO      36    36\n",
      "        MI-GNN     1 × 10−3    1 × 10−2   0.35         3       Conv2d(3, 1, 0) + ReLU       36    48\n",
      "                                                       4       MaxPool2d(2, 2, 0) + DO      48    48\n",
      "        Table A21: CRC MI-Net architecture.\n",
      "                                                           Table A22: CRC mi-Net architecture.\n",
      "      Layer Type                  Input Output\n",
      "                                                         Layer Type                   Input Output\n",
      "      1       FC + ReLU + DO      1200   64\n",
      "                                                         1        FC + ReLU + DO      1200    64\n",
      "      2       FC + ReLU + DO      64     512\n",
      "                                                         2        FC + ReLU + DO      64      64\n",
      "      3       mil-max             512    512\n",
      "                                                         3        FC + ReLU + DO      64      64\n",
      "      4       FC + ReLU + DO      512    128\n",
      "                                                         4        FC                  64      2\n",
      "      4       FC + ReLU + DO      128    64\n",
      "                                                         5        mil-max             2       2\n",
      "      4       FC + ReLU + DO      64     2\n",
      "                                                   19\n",
      "\n",
      "Published as a preprint\n",
      "                               Table A23: CRC MI-Attn architecture.\n",
      "                       Layer Type                       Input size Output size\n",
      "                       1      FC + ReLU + Dropout       1200        64\n",
      "                       2      FC + ReLU + Dropout       64          64\n",
      "                       3      FC + ReLU + Dropout       64          256\n",
      "                       4      mil-attn(128) + Dropout   256         256\n",
      "                       5      FC                        256         2\n",
      "                              Table A24: CRC MI-GNN architecture.\n",
      "               Layer          Type                              Input size Output size\n",
      "               1              FC + ReLU + Dropout               1200       64\n",
      "               2              FC + ReLU + Dropout               64         128\n",
      "               3a GNNembed SAGEConv + ReLU + Dropout 128                   128\n",
      "               3b GNNcluster SAGEConv + Softmax                 128        1\n",
      "               4              gnn-pool                          128        128\n",
      "               5              FC + ReLU + Dropout               128        128\n",
      "               6              FC                                128        2\n",
      "Table A25: CRC model results. The mean performance was calculated over ten repeat trainings of\n",
      "each model, and the standard error of the mean is given.\n",
      "                      Model     Train Accuracy Val Accuracy Test Accuracy\n",
      "                      MI-Net    0.880 ± 0.041     0.805 ± 0.034   0.795 ± 0.042\n",
      "                      mi-Net    0.856 ± 0.041     0.810 ± 0.043   0.795 ± 0.049\n",
      "                      MI-Attn   0.870 ± 0.014     0.860 ± 0.017   0.830 ± 0.028\n",
      "                      MI-GNN    0.791 ± 0.039     0.765 ± 0.031   0.770 ± 0.032\n",
      "A.9    A DDITIONAL EXPERIMENTS\n",
      "In this section, we provide additional sample size experiments for the SIVAL, 4-MNIST-Bags, and\n",
      "CRC datasets for MI-Net (Figure A1), mi-Net (Figure A2), and MI-GNN (Figure A3). We find\n",
      "the trends are relatively consistent across all the models. GuidedSHAP and MILLI are the most\n",
      "consistent and well performing methods, and MILLI is particularly effective on the 4-MNIST-Bags\n",
      "dataset. One considerable difference is the performance of RandomLIME and GuidedLIME on the\n",
      "CRC dataset for the MI-GNN model; for all other models, both LIME methods perform poorly on\n",
      "the CRC dataset. Further investigation is required to understand why this happens. However, the\n",
      "LIME methods are still outperformed by MILLI and GuidedSHAP on the CRC dataset, even for the\n",
      "MI-GNN model.\n",
      "          Figure A1: The effect of sample size on interpretability performance for MI-Net.\n",
      "                                                  20\n",
      "\n",
      "Published as a preprint\n",
      "          Figure A2: The effect of sample size on interpretability performance for mi-Net.\n",
      "         Figure A3: The effect of sample size on interpretability performance for MI-GNN.\n",
      "A.10     A DDITIONAL OUTPUTS\n",
      "In this section, we provide additional interpretability outputs from our studies, similar to the one\n",
      "in Section 5. First, we provide additional outputs for the 4-MNIST-Bags dataset. Then, we show\n",
      "the interpretability outputs for the SIVAL and CRC datasets. The SIVAL outputs are created by\n",
      "ranking the instances in a bag according to some interpretability function (i.e., by using MILLI),\n",
      "and then selecting the top n, where n is the known number of key instances in the bag. Then, the\n",
      "corresponding segment for each instance is weighted by the function log2 (i + 1)−1 , where i is the\n",
      "instance’s position in the ranking (this is the same scaling used in NDCG@n). The other instances all\n",
      "received a weighting of zero. The brightness of each segment in the output image then corresponds\n",
      "with its relative importance according to the interpretability method. For the CRC interpretability\n",
      "outputs, the important patches are found by using an interpretability method to output the top n\n",
      "patches that support a particular class, where n is the number of known important instances for that\n",
      "class. We then highlight these patches while dimming the other patches to produce an interpretation\n",
      "of the model’s decision-making.\n",
      "Figure A4: The interpretability output for a class two bag on the 4-MNIST-Bags experiment. The\n",
      "top row shows the attention value for each instance, and bottom two rows show the output of MILLI\n",
      "for classes two and zero respectively (green = support, red = refute). We can see that both Attention\n",
      "and MILLI have identified the 9s as important, but only MILLI is able to also say that the 9s support\n",
      "class two and refute class zero.\n",
      "                                                    21\n",
      "\n",
      "Published as a preprint\n",
      "Figure A5: The interpretability output for a class one bag on the 4-MNIST-Bags experiment. We\n",
      "can see that both Attention and MILLI have identified the 8s as important, but only MILLI is able to\n",
      "also say that the 8s support class one and refute class zero. Also note that the colours are less strong\n",
      "for the final 8 — the digit is partially obscured, so the model is less confident.\n",
      "Figure A6: The interpretability output for two examples of the cokecan class in the SIVAL dataset.\n",
      "The first column shows the original images, the second column the ground truth segments that\n",
      "contain the object, and the final column is the output from MILLI. The interpretations show the\n",
      "model is relying heavily on the colour red as an indicator of the object’s location, as it also picks up\n",
      "on the red in the background as being important.\n",
      "                                                    22\n",
      "\n",
      "Published as a preprint\n",
      "Figure A7: The interpretability output for two examples of the dataminingbook class in the SIVAL\n",
      "dataset. Again, the interpretations show the model is relying heavily on the colour orange as an indi-\n",
      "cator of the object’s location, as it also picks up on the similar colours in the background, including\n",
      "the reflection of the book in the table.\n",
      "Figure A8: The interpretability output for two examples of the goldmedal class in the SIVAL dataset.\n",
      "Here, the interpretations show the model is ignoring the gold medal itself, and instead focusing on\n",
      "the red ribbon, i.e., if it were shown the medal without the ribbon, it would likely misclassify it.\n",
      "                                                    23\n",
      "\n",
      "Published as a preprint\n",
      "Figure A9: The interpretability output for two examples of the wd40can class in the SIVAL dataset.\n",
      "Here, the interpretations show the model is predominantly focusing on the strong yellow colour at\n",
      "the top of the can, and sometimes picks out the letters and red cap. The rest of the bottle is largely\n",
      "ignored, meaning if the top half were obscured, the model would likely misclassify it.\n",
      "Figure A10: The interpretability output for an image in the CRC dataset. From left to right, the\n",
      "figures shows: the original image, the image with background patches removed, the ground truth\n",
      "patches for the image’s label, and the interpretability output from MILLI. In this example, the image\n",
      "is class zero (i.e., non-epithelial), meaning the highlighted patches contain mostly fibroblast and\n",
      "inflammatory nuclei. As shown here, MILLI has identified that the model is using the same patches\n",
      "as the ground truth to make a decision, indicating that the model has learnt to correctly identify\n",
      "fibroblast and inflammatory nuclei as supporting instances for non-epithelial images.\n",
      "                                                  24\n",
      "\n",
      "Published as a preprint\n",
      "Figure A11: The interpretability output for a positive image in the CRC dataset. In this example, the\n",
      "ground truth patches all contain at least one epithelial nuclei. MILLI has identified that the model is\n",
      "using most of the same patches as the ground truth to make a decision, indicating that the model has\n",
      "learnt to correctly identify epithelial nuclei as supporting class one.\n",
      "Figure A12: The interpretability output for a negative image in the CRC dataset. In this example,\n",
      "the patches are sparse — there are a lot of background patches that are removed, and the key patches\n",
      "are spread out (as opposed to being connected as in the previous examples). Again, MILLI is able\n",
      "to correctly identify the patches that support the negative class.\n",
      "Figure A13: The interpretability output for a positive image in the CRC dataset. In this example,\n",
      "MILLI has identified some of the ground truth patches, but also additional patches that are not\n",
      "labelled as epithelial in the ground truth labelling. As the labelling was not exhaustive, these patches\n",
      "may contain epithelial nuclei without being labelled as such. By using MILLI, it is apparent that\n",
      "the model is using these patches in its decision-making, therefore further investigation into the types\n",
      "of nuclei in these patches would reveal more information about how the model makes its decisions;\n",
      "something that would not be possible without the interpretability output.\n",
      "                                                    25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = pdf_content\n",
    "doc = nlp(text)\n",
    "words = []\n",
    "labels = []\n",
    "print(doc)\n",
    "for token in doc:\n",
    "\twords.append(token.text)\n",
    "\tlabels.append('O') # As most of token will be non-entity (OUT). Replace this later with actual entity a/c the scheme.\n",
    "\n",
    "df = pd.DataFrame({'word': words, 'label': labels})\n",
    "df.to_csv('ner-token-per-line.biluo', index=False) # biluo in extension to indicate the type of encoding, it is ok to keep csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f133bdb-5f31-4c68-aa49-845776493b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas TLA\n",
    "\n",
    "# preprocessing\n",
    "    # cleaning\n",
    "\n",
    "# Tools - textcleaner , clean text, classical packages. if I need to clean the text ?\n",
    "# Nettoyage a faire : enlever les deux colonnes ? \n",
    "# enlever les references, ou au contraire travailler sur les references (comparer les 2 cas)\n",
    "\n",
    "# Make a NLP model? \n",
    "# extraction of (LABELLING FOR 20 PDF)\n",
    "    # names, \n",
    "    # places, \n",
    "    # relations (work together, refenrenced), \n",
    "    # dates\n",
    "\n",
    "# Utiliser spaCy, et le specifier a mon cas\n",
    "# il existe des spacy projects avec API.... a voir\n",
    "# il existe des facon de visualiser les liens entre les entites nommes sur spacy\n",
    "\n",
    "# Tokenisation\n",
    "\n",
    "\n",
    "# At the end \n",
    "# cleaning : doublons\n",
    "\n",
    "# Pipeline :\n",
    "# Text -  [tokenizer - tagger - parser - ner - ....] - Doc "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f21731382a87e7217c69335d4612f3e19df9b758c98057a2e59c665d7481a489"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('filerougevenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
